{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jjjonathan14/crowdhuman_tensorRT/blob/main/jesus.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CC-_AWUYGYEE",
        "outputId": "3f13da9c-39e5-4c31-e1ea-f5a9bab4b93f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UTJ3P5mEP2Mc",
        "outputId": "bad4c481-ff14-4371-dbed-1817dfe5343d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting einops\n",
            "  Downloading einops-0.4.1-py3-none-any.whl (28 kB)\n",
            "Installing collected packages: einops\n",
            "Successfully installed einops-0.4.1\n"
          ]
        }
      ],
      "source": [
        "!pip install einops"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "beuhltGzJZtA"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch import nn\n",
        "from torch import Tensor\n",
        "from torchvision.transforms import Compose, Resize, ToTensor\n",
        "from einops import rearrange, reduce, repeat\n",
        "from einops.layers.torch import Rearrange, Reduce\n",
        "\n",
        "class PatchEmbedding(nn.Module):\n",
        "    def __init__(self, in_channels: int = 3, patch_size: int = 16, emb_size: int = 768, img_size: int = 224):\n",
        "        self.patch_size = patch_size\n",
        "        super().__init__()\n",
        "        self.projection = nn.Sequential(\n",
        "            # using a conv layer instead of a linear one -> performance gains\n",
        "            nn.Conv2d(in_channels, emb_size, kernel_size=patch_size, stride=patch_size),\n",
        "            Rearrange('b e (h) (w) -> b (h w) e'),\n",
        "        )\n",
        "        self.cls_token = nn.Parameter(torch.randn(1 ,1, emb_size))\n",
        "        self.positions = nn.Parameter(torch.randn((img_size // patch_size) **2 + 1, emb_size))\n",
        "\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        b, _, _, _ = x.shape\n",
        "\n",
        "        x = self.projection(x)\n",
        "        cls_tokens = repeat(self.cls_token, '() n e -> b n e', b=b)\n",
        "        # prepend the cls token to the input\n",
        "        x = torch.cat([cls_tokens, x], dim=1)\n",
        "        # add position embedding\n",
        "        x += self.positions\n",
        "        return x\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, emb_size: int = 768, num_heads: int = 8, dropout: float = 0):\n",
        "        super().__init__()\n",
        "        self.emb_size = emb_size\n",
        "        self.num_heads = num_heads\n",
        "        # fuse the queries, keys and values in one matrix\n",
        "        self.qkv = nn.Linear(emb_size, emb_size * 3)\n",
        "        self.att_drop = nn.Dropout(dropout)\n",
        "        self.projection = nn.Linear(emb_size, emb_size)\n",
        "\n",
        "    def forward(self, x : Tensor, mask: Tensor = None) -> Tensor:\n",
        "        # split keys, queries and values in num_heads\n",
        "        qkv = rearrange(self.qkv(x), \"b n (h d qkv) -> (qkv) b h n d\", h=self.num_heads, qkv=3)\n",
        "        queries, keys, values = qkv[0], qkv[1], qkv[2]\n",
        "        # sum up over the last axis\n",
        "        energy = torch.einsum('bhqd, bhkd -> bhqk', queries, keys) # batch, num_heads, query_len, key_len\n",
        "        if mask is not None:\n",
        "            fill_value = torch.finfo(torch.float32).min\n",
        "            energy.mask_fill(~mask, fill_value)\n",
        "\n",
        "        scaling = self.emb_size ** ( 1 /2)\n",
        "        att = F.softmax(energy, dim=-1) / scaling\n",
        "        att = self.att_drop(att)\n",
        "        # sum up over the third axis\n",
        "        out = torch.einsum('bhal, bhlv -> bhav ', att, values)\n",
        "        out = rearrange(out, \"b h n d -> b n (h d)\")\n",
        "        out = self.projection(out)\n",
        "        return out\n",
        "\n",
        "class ResidualAdd(nn.Module):\n",
        "    def __init__(self, fn):\n",
        "        super().__init__()\n",
        "        self.fn = fn\n",
        "\n",
        "    def forward(self, x, **kwargs):\n",
        "        res = x\n",
        "        x = self.fn(x, **kwargs)\n",
        "        x += res\n",
        "        return x\n",
        "\n",
        "class FeedForwardBlock(nn.Sequential):\n",
        "    def __init__(self, emb_size: int =768, expansion: int = 4, drop_p: float = 0.):\n",
        "        super().__init__(\n",
        "            nn.Linear(emb_size, expansion * emb_size),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(drop_p),\n",
        "            nn.Linear(expansion * emb_size, emb_size),\n",
        "        )\n",
        "\n",
        "class TransformerEncoderBlock(nn.Sequential):\n",
        "    def __init__(self,\n",
        "                 emb_size: int = 768,\n",
        "                 drop_p: float = 0.,\n",
        "                 forward_expansion: int = 4,\n",
        "                 forward_drop_p: float = 0.,\n",
        "                 ** kwargs):\n",
        "        super().__init__(\n",
        "            ResidualAdd(nn.Sequential(\n",
        "                nn.LayerNorm(emb_size),\n",
        "                MultiHeadAttention(emb_size, **kwargs),\n",
        "                nn.Dropout(drop_p)\n",
        "            )),\n",
        "            ResidualAdd(nn.Sequential(\n",
        "                nn.LayerNorm(emb_size),\n",
        "                FeedForwardBlock(\n",
        "                    emb_size, expansion=forward_expansion, drop_p=forward_drop_p),\n",
        "                nn.Dropout(drop_p)\n",
        "            )\n",
        "            ))\n",
        "\n",
        "class TransformerEncoder(nn.Sequential):\n",
        "    def __init__(self, depth: int = 12, **kwargs):\n",
        "        super().__init__(*[TransformerEncoderBlock(**kwargs) for _ in range(depth)])\n",
        "\n",
        "class ClassificationHead(nn.Sequential):\n",
        "    def __init__(self, emb_size: int = 768, n_classes: int = 1000):\n",
        "        super().__init__(\n",
        "            Reduce('b n e -> b e', reduction='mean'),\n",
        "            nn.LayerNorm(emb_size),\n",
        "            nn.Linear(emb_size, n_classes))\n",
        "\n",
        "class ViT(nn.Sequential):\n",
        "    def __init__(self,\n",
        "                 in_channels: int = 64,\n",
        "                 patch_size: int = 16,\n",
        "                 emb_size: int = 768,\n",
        "                 img_size: int = 56,\n",
        "                 depth: int = 12,\n",
        "                 n_classes: int = 1000,\n",
        "                 **kwargs):\n",
        "        super().__init__(\n",
        "            PatchEmbedding(in_channels, patch_size, emb_size, img_size),\n",
        "            TransformerEncoder(depth, emb_size=emb_size, **kwargs),\n",
        "            ClassificationHead(emb_size, n_classes)\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "yBGBKDYKJj8o"
      },
      "outputs": [],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"j-Hybrid.ipynb\n",
        "\n",
        "Automatically generated by Colaboratory.\n",
        "\n",
        "Original file is located at\n",
        "    https://colab.research.google.com/drive/1Ola5OebLU1VOKCpQ2RvDJVRj8Myhpugk\n",
        "\"\"\"\n",
        "\n",
        "# !pip install einops\n",
        "import random\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from torch import nn\n",
        "from torch import Tensor\n",
        "from PIL import Image\n",
        "from torchvision.transforms import Compose, Resize, ToTensor\n",
        "from einops import rearrange, reduce, repeat\n",
        "from einops.layers.torch import Rearrange, Reduce\n",
        "import numpy as np\n",
        "import torch\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "import torch.nn as nn\n",
        "import torch\n",
        "import math\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "def batch_plot(img,n, h, w):\n",
        "  fig = plt.figure(figsize=(n, n))\n",
        "  columns = n\n",
        "  rows = n\n",
        "  for i in range(1, columns*rows):\n",
        "\n",
        "      fig.add_subplot(rows, columns, i)\n",
        "      plt.imshow(img[i])\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "\n",
        "arr = torch.rand(1, 1, 28, 28)\n",
        "\n",
        "class Hybrid(nn.Module):\n",
        "    \"\"\"\n",
        "    block: A sub module\n",
        "    \"\"\"\n",
        "    def __init__(self, inchannels = 1,n_classes = 10, embedding = 96):\n",
        "        super(Hybrid, self).__init__()\n",
        "        # self.conv1 = nn.Conv2d(inchannels, 64, kernel_size = 7, stride = 2, padding = 3,\n",
        "        #                        bias = False)\n",
        "        # self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "\n",
        "        # self.patchEmbedding1 = PatchEmbedding(inchannels, 8, embedding, 224)\n",
        "        self.transformerEncoder = TransformerEncoderBlock(embedding, 0.0, 4, 0.0)\n",
        "        self.maxpool1 = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "\n",
        "        # self.conv2 = nn.Conv2d(64, 128, kernel_size=1, bias=False)\n",
        "        # self.bn2 = nn.BatchNorm2d(128)\n",
        "        # self.patchEmbedding2 = PatchEmbedding(64, 8, embedding, 56)\n",
        "        # self.conv22 = nn.Conv2d(128, 128, kernel_size=1, bias=False)\n",
        "        # self.conv222 = nn.Conv2d(128, 128, kernel_size=3, padding=1, bias=False)\n",
        "\n",
        "        self.conv3 = nn.Conv2d(inchannels, 16, kernel_size=1, bias=False)\n",
        "        self.bn3 = nn.BatchNorm2d(16)\n",
        "        self.patchEmbedding3 = PatchEmbedding(inchannels, 8, embedding, 28)\n",
        "        self.conv33 = nn.Conv2d(16, 16, kernel_size=1, bias=False)\n",
        "        self.conv333 = nn.Conv2d(16, 16, kernel_size=3, padding=1, bias=False)\n",
        "        \n",
        "\n",
        "\n",
        "\n",
        "        self.conv4 = nn.Conv2d(16, 32, kernel_size=1, bias=False)\n",
        "        self.bn4 = nn.BatchNorm2d(32)\n",
        "        self.patchEmbedding4 = PatchEmbedding(16, 8, embedding, 14)\n",
        "        self.conv44 = nn.Conv2d(32, 32, kernel_size=1, bias=False)\n",
        "        self.conv444 = nn.Conv2d(32, 32, kernel_size=3, padding=1, bias=False)\n",
        "\n",
        "\n",
        "        self.conv5 = nn.Conv2d(32, 64, kernel_size=1, bias=False)\n",
        "        self.bn5 = nn.BatchNorm2d(64)\n",
        "        self.patchEmbedding5 = PatchEmbedding(32, 3, embedding, 7)\n",
        "        self.conv55 = nn.Conv2d(64, 64, kernel_size=1, bias=False)\n",
        "        self.conv555 = nn.Conv2d(64, 64, kernel_size=3, padding=1, bias=False)\n",
        "\n",
        "        self.nn1 = nn.Linear(1024, 512)\n",
        "        self.nn2 = nn.Linear(512, n_classes)\n",
        "\n",
        "\n",
        "        self.nny1_1 = nn.Linear(75360, 7500)\n",
        "        self.nny1_2 = nn.Linear(7500, 480)\n",
        "        self.nny2 = nn.Linear(4800, 480)\n",
        "        self.nny3 = nn.Linear(960, 480)\n",
        "        self.nny4 = nn.Linear(192, 480)\n",
        "\n",
        "        self.nnR = nn.Linear(480, 480)\n",
        "        self.nnY1 = nn.Linear(480, 48)\n",
        "        self.nnY2 = nn.Linear(48, n_classes)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "        #self.classificationhead = ClassificationHead(emb_size = 768, n_classes = 1000)\n",
        "\n",
        "        self.dropout = nn.Dropout(p=0.1)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        # y = x\n",
        "        # x = self.conv1(x)\n",
        "        # x = self.bn1(x)\n",
        "        # x = self.relu(x)\n",
        "        # x = self.maxpool(x)\n",
        "        # y = self.patchEmbedding1(y)\n",
        "        # y1 = self.transformerEncoder(y)\n",
        "        # y1 = self.transformerEncoder(y1)\n",
        "        # y1 = torch.flatten(y1, start_dim=1)\n",
        "        # y1 = self.nny1_1(y1)\n",
        "        # y1 = self.nny1_2(y1)\n",
        "\n",
        "\n",
        "        # y = x\n",
        "        # x = self.conv2(x)\n",
        "        # x = self.bn2(x)\n",
        "        # z1 = x\n",
        "        # r = x\n",
        "        # z1 = self.conv22(z1)\n",
        "        # z1 = self.bn2(z1)\n",
        "        # z1 = self.conv222(z1)\n",
        "        # z1 = self.bn2(z1)\n",
        "        # z1 = self.conv22(z1)\n",
        "        # z1 = self.bn2(z1)\n",
        "        # x = r + z1\n",
        "        # x = self.maxpool1(x)\n",
        "        # y = self.patchEmbedding2(y)\n",
        "        # y2 = self.transformerEncoder(y)\n",
        "        # y2 = self.transformerEncoder(y2)\n",
        "        # y2 = torch.flatten(y2, start_dim=1)\n",
        "        # y2 = self.nny2(y2)\n",
        "        # y2 = y1 + y1\n",
        "        # y2 = self.nnR(y2)\n",
        "\n",
        "\n",
        "        y = x\n",
        "        #print('x input', x.shape)\n",
        "        x = self.conv3(x)\n",
        "        x = self.bn3(x)\n",
        "        t = x\n",
        "        #print('conv3 shape', x.shape, x[0].shape)\n",
        "        #batch_plot(t[0].detach().cpu().numpy(), 16, 28, 28)\n",
        "        z2 = x\n",
        "        r = x\n",
        "        z2 = self.conv33(z2)\n",
        "        z2 = self.relu(self.bn3(z2))\n",
        "        z2 = self.conv333(z2)\n",
        "        z2 = self.relu(self.bn3(z2))\n",
        "        z2 = self.conv33(z2)\n",
        "        z2 = self.relu(self.bn3(z2))\n",
        "        x = r + z2\n",
        "        x = self.maxpool1(x)\n",
        "        y = self.patchEmbedding3(y)\n",
        "        y3 = self.transformerEncoder(y)\n",
        "        y3 = self.transformerEncoder(y3)\n",
        "        y3 = torch.flatten(y3, start_dim=1)\n",
        "        #print('y3 transformer', y3.shape)\n",
        "        y3 = self.dropout(self.relu(self.nny3(y3)))\n",
        "        #y3 = y2 + y3\n",
        "        y3 = self.dropout(self.relu(self.nnR(y3)))\n",
        "\n",
        "\n",
        "        y = x\n",
        "        x = self.conv4(x)\n",
        "        x = self.bn4(x)\n",
        "        z3 = x\n",
        "        r = x\n",
        "        z3 = self.conv44(z3)\n",
        "        z3 = self.relu(self.bn4(z3))\n",
        "        z3 = self.conv444(z3)\n",
        "        z3 = self.relu(self.bn4(z3))\n",
        "        z3 = self.conv44(z3)\n",
        "        z3 = self.relu(self.bn4(z3))\n",
        "        x = r + z3\n",
        "        x = self.maxpool1(x)\n",
        "        y = self.patchEmbedding4(y)\n",
        "        y4 = self.transformerEncoder(y)\n",
        "        y4 = self.transformerEncoder(y4)\n",
        "        y4 = torch.flatten(y4, start_dim=1)\n",
        "        #print('y4 transformer', y4.shape)\n",
        "        y4 = self.dropout(self.relu(self.nny4(y4)))\n",
        "        y4 = y3 + y4\n",
        "        y4 = self.dropout(self.relu(self.nnR(y4)))\n",
        "\n",
        "\n",
        "        y = x\n",
        "        x = self.conv5(x)\n",
        "        x = self.bn5(x)\n",
        "        z4 = x\n",
        "        r = x\n",
        "        z4 = self.conv55(z4)\n",
        "        z4 = self.relu(self.bn5(z4))\n",
        "        t1 = x\n",
        "        #batch_plot(t1[0].detach().cpu().numpy(), 32, 7, 7)\n",
        "        z4 = self.conv555(z4)\n",
        "        z4 = self.relu(self.bn5(z4))\n",
        "        z4 = self.conv55(z4)\n",
        "        z4 = self.relu(self.bn5(z4))\n",
        "        x = r + z4\n",
        "        x = self.maxpool1(x)\n",
        "        X = torch.flatten(x, start_dim=1)\n",
        "        #print('X', X.shape)\n",
        "        y = self.patchEmbedding5(y)\n",
        "        y5 = self.transformerEncoder(y)\n",
        "        y5 = self.transformerEncoder(y5)\n",
        "        y5 = torch.flatten(y5, start_dim=1)\n",
        "        #print('y5 transformer encoder', y5.shape)\n",
        "\n",
        "        y5 = y4 + y5\n",
        "        y5 = self.dropout(self.relu(self.nnR(y5)))\n",
        "\n",
        "        Y = self.dropout(self.relu(self.nnY1(y5)))\n",
        "        Y = self.dropout(self.relu(self.nnY2(Y)))\n",
        "        Y = self.sigmoid(Y)\n",
        "\n",
        "\n",
        "        X = self.dropout(self.relu(self.nn1(X)))\n",
        "        X = self.sigmoid(self.nn2(X))\n",
        "\n",
        "\n",
        "        Z = X + Y\n",
        "\n",
        "        return X, Y, Z\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Hybrid()"
      ],
      "metadata": {
        "id": "B1FS8gN3HI4X"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res = model(arr)"
      ],
      "metadata": {
        "id": "YaxdZ2R2HTjI"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cCZ_LqOPJnpK",
        "outputId": "ebac661e-8dfa-4989-e689-42a5a3c05517"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "memorize 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r0it [00:00, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:982: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([1, 10])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.huber_loss(input, target, reduction=self.reduction, delta=self.delta)\n",
            "9984it [00:36, 299.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 10000] count 1001 loss hybrid: 514.4837219119072 loss ssl: 0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "20096it [01:05, 393.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 20000] count 993 loss hybrid: 509.7196875810623 loss ssl: 0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "30035it [01:31, 459.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 30000] count 967 loss hybrid: 496.72572407126427 loss ssl: 0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "40039it [01:59, 367.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 40000] count 963 loss hybrid: 493.88485211133957 loss ssl: 0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "50063it [02:27, 343.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 50000] count 1008 loss hybrid: 518.4754061102867 loss ssl: 0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "60000it [02:54, 344.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 60000] count 991 loss hybrid: 508.78575336933136 loss ssl: 0.0\n",
            "memorize 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "10042it [00:27, 298.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 10000] count 1001 loss hybrid: 125.62804920971394 loss ssl: 0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "20057it [00:54, 365.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 20000] count 993 loss hybrid: 124.125 loss ssl: 0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "30032it [01:21, 452.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 30000] count 967 loss hybrid: 120.875 loss ssl: 0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "40040it [01:47, 340.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 40000] count 963 loss hybrid: 120.375 loss ssl: 0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "50034it [02:15, 369.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 50000] count 1008 loss hybrid: 126.0 loss ssl: 0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "60000it [02:42, 368.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 60000] count 991 loss hybrid: 123.875 loss ssl: 0.0\n",
            "memorize 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "10036it [00:27, 281.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 10000] count 1001 loss hybrid: 125.125 loss ssl: 0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "20086it [00:54, 397.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 20000] count 993 loss hybrid: 124.125 loss ssl: 0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "30057it [01:21, 403.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 30000] count 967 loss hybrid: 120.875 loss ssl: 0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "40039it [01:47, 362.99it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 40000] count 963 loss hybrid: 120.375 loss ssl: 0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "50067it [02:15, 339.88it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 50000] count 1008 loss hybrid: 126.0 loss ssl: 0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "51901it [02:20, 336.36it/s]"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "# from jesus import Hybrid\n",
        "import torch.optim as optim\n",
        "import cv2\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "batch_size = 1\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "  torchvision.datasets.MNIST('/files/', train=True, download=True,\n",
        "                             transform=torchvision.transforms.Compose([\n",
        "                               torchvision.transforms.ToTensor(),\n",
        "                               #torchvision.transforms.Resize((224,224)),\n",
        "                               torchvision.transforms.Normalize(\n",
        "                                 (0.1307,), (0.3081,)),\n",
        "                             ])),\n",
        "  batch_size=batch_size, shuffle=False)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "  torchvision.datasets.MNIST('/files/', train=False, download=True,\n",
        "                             transform=torchvision.transforms.Compose([\n",
        "                               torchvision.transforms.ToTensor(),\n",
        "                               #torchvision.transforms.Resize((224,224)),\n",
        "                               torchvision.transforms.Normalize(\n",
        "                                 (0.1307,), (0.3081,))\n",
        "                             ])),\n",
        "  batch_size=batch_size, shuffle=False)\n",
        "classes = ('0', '1', '2', '3',\n",
        "           '4', '5', '6', '7', '8', '9')\n",
        "\n",
        "\n",
        "def imshow(img):\n",
        "    img = img / 2 + 0.5     # unnormalize\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()\n",
        "\n",
        "model = Hybrid()\n",
        "model.cuda()\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "criterion_hybrid = nn.HuberLoss()\n",
        "#optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "for epoch in range(100):  # loop over the dataset multiple times\n",
        "    \n",
        "    t = epoch % 9\n",
        "    if epoch < 10:\n",
        "      n = 10\n",
        "      \n",
        "    elif epoch < 20:\n",
        "      n =7\n",
        "      \n",
        "    elif epoch < 30:\n",
        "      n = 5\n",
        "      \n",
        "    else:\n",
        "      n = 3\n",
        "      \n",
        "    for memorize in range(n):\n",
        "          if epoch < 10:\n",
        "            optimizer = optim.Adam(model.parameters(), lr=0.01*memorize)\n",
        "\n",
        "          elif epoch < 20:\n",
        "            optimizer = optim.Adam(model.parameters(), lr=0.001*memorize)\n",
        "\n",
        "          elif epoch < 30:\n",
        "            optimizer = optim.Adam(model.parameters(), lr=0.0001*memorize)\n",
        "\n",
        "          else:\n",
        "            optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
        "\n",
        "          running_loss_hybrid = 0.0\n",
        "          running_loss_cnn = 0.0\n",
        "          running_loss_vit = 0.0\n",
        "          running_loss_ssl = 0.0\n",
        "          count = 0\n",
        "          print('memorize', memorize)\n",
        "          for i, data in tqdm(enumerate(train_loader, 0)):\n",
        "              # get the inputs; data is a list of [inputs, labels]\n",
        "              if i % 10000 == 9999:    # print every 2000 mini-batches\n",
        "                  print(f'[{epoch + 1}, {i + 1:5d}] count {count} loss hybrid: {running_loss_hybrid} loss ssl: {running_loss_ssl}')\n",
        "                  with open('/content/drive/MyDrive/self_learning/result.txt','a') as f:\n",
        "                    f.write(f'[{epoch + 1}, {i + 1:5d}] count {count} loss hybrid:  {running_loss_hybrid} loss ssl:  {running_loss_ssl}')\n",
        "                  running_loss_hybrid = 0.0\n",
        "                  running_loss_cnn = 0.0\n",
        "                  running_loss_vit = 0.0\n",
        "                  running_loss_ssl = 0.0\n",
        "\n",
        "                  count = 0\n",
        "\n",
        "                  # correct = 0\n",
        "                  # total = 0\n",
        "                  # # since we're not training, we don't need to calculate the gradients for our outputs\n",
        "                  # with torch.no_grad():\n",
        "                  #     for data in test_loader:\n",
        "                  #         images, labels = data\n",
        "                  #         inputs, labels = inputs.cuda(), labels.cuda()\n",
        "                  #         # calculate outputs by running images through the network\n",
        "                  #         outputs = Hybrid(images)\n",
        "                  # #         # the class with the highest energy is what we choose as prediction\n",
        "                  #         _, predicted = torch.max(outputs.data, 1)\n",
        "                  #         total += labels.size(0)\n",
        "                  #         correct += (predicted == labels).sum().item()\n",
        "\n",
        "                  # print(f'Accuracy of the network on the 10000 test images: {100 * correct // total} %')\n",
        "                  # with open('/content/drive/MyDrive/self_learning/accuracy','a') as w:\n",
        "                  #   w.write(f'[{epoch + 1}, {i + 1:5d}] count {count} loss hybrid: {running_loss_hybrid / count:.3f} loss cnn: {running_loss_cnn / count:.3f} loss vit: {running_loss_vit / count:.3f} \\n ')\n",
        "                  \n",
        "\n",
        "              inputs, labels = data\n",
        "              if not labels == t:\n",
        "                continue\n",
        "              count += 1\n",
        "              inputs, labels = inputs.cuda(), labels.cuda()\n",
        "\n",
        "              # zero the parameter gradients\n",
        "              # optimizer.zero_grad()\n",
        "              # forward + backward + optimize\n",
        "              #optimizer.zero_grad()\n",
        "              X, Y, Z = model(inputs)\n",
        "              labels = labels.to(torch.float32)\n",
        "              loss1 = criterion_hybrid(Z, labels)\n",
        "              loss1.backward()\n",
        "              optimizer.step()\n",
        "              running_loss_hybrid += loss1.item()\n",
        "\n",
        "              # forward + backward + optimize\n",
        "              #optimizer.zero_grad()\n",
        "              # X, Y, Z = model(inputs)\n",
        "              # loss2 = criterion(X, Z)\n",
        "              # loss2.backward()\n",
        "              # optimizer.step()\n",
        "              # running_loss_cnn += loss2.item()\n",
        "\n",
        "              # # forward + backward + optimize\n",
        "              # #optimizer.zero_grad()\n",
        "              # X, Y, Z = model(inputs)\n",
        "              # loss3 = criterion(Y, X)\n",
        "              # loss3.backward()\n",
        "              # optimizer.step()\n",
        "              # running_loss_vit += loss3.item()\n",
        "#self supervisied \n",
        "              # X, Y, Z = model(inputs)\n",
        "              # loss4 = criterion(Y, X)\n",
        "              # #print('loss ssl', loss4)\n",
        "              # loss4.backward()\n",
        "              # optimizer.step()\n",
        "              # running_loss_ssl += loss4.item()\n",
        "\n",
        "              # print statistics\n",
        "              \n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "P4O5eSo6OymH"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "background_execution": "on",
      "collapsed_sections": [],
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}